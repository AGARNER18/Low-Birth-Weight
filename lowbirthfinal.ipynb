{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Low Birth Weight\n",
    "# The data on 189 births were collected at Baystate Medical Center, Springfield, Mass. during 1986. \n",
    "# The dataset contains an indicator of low infant birth weight as a response and several risk factors associated with low birth weight. \n",
    "# The actual birth weight is also included in the dataset. \n",
    "# Reference: http://www.statlab.uni-heidelberg.de/data/linmod/birthweight.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Machine Learning Library of PySpark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.sql import Row, SQLContext\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Library for confusion matrix, precision, test error\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "# Library For Area under ROC curve and Area under precision-recall curve\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "# Assign resources to the application\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'ID,LOW,AGE,RACE,SMOKE,PTL,HT,UI,FTV',\n",
       " u'85,0,19,2,0,0,0,1,0',\n",
       " u'86,0,33,3,0,0,0,0,3',\n",
       " u'87,0,20,1,1,0,0,0,1',\n",
       " u'88,0,21,1,1,0,0,1,2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The data will be loaded into an array.\n",
    "# This is the summary of the data structure, including the column position and name.\n",
    "# The first filed starts from position 0. \n",
    "\n",
    "# 0 ID  \n",
    "# 1 LOW   -  1 if birth weight below 2.5kg; 0 if birth weight below 2.5 kg\n",
    "# 2 AGE   -  age of mother in years\n",
    "# 3 RACE  -  race of mother (white=1,black=2, other=3)\n",
    "# 4 SMOKE -  1 if the mother smoked;  0 if the mother did not smoke\n",
    "# 5 PTL   -  number of previous premature labours for mother\n",
    "# 6 HT    -  1 if history of hypertension for mother; 0 if no history of hypertension for mother\n",
    "# 7 UI    -  1 if presence of uterine irrability; 0 if no presence of uterine irrability\n",
    "# 8 FTB   -  number of physicians visist during first trimester\n",
    "\n",
    "# Label is a target variable.  PersonInfo is a list of independent variables besides unique identifier\n",
    "\n",
    "LabeledDocument = Row(\"PersonID\", \"PersonInfo\", \"label\")\n",
    "\n",
    "# Define a function that parses the raw CSV file and returns an object of type LabeledDocument\n",
    "\n",
    "def parseDocument(line):\n",
    "    values = [str(x) for x in line.split(',')] \n",
    "    if (values[1]>'0'):\n",
    "      low_birth = 1.0\n",
    "    else:\n",
    "     low_birth = 0.0\n",
    "        \n",
    "    textValue = str(values[2]) + \" \" + str(values[3])+\" \" + str(values[4])+\" \" + str(values[5])+\" \" + str(values[6])+\" \" + str(values[7])+\" \" + str(values[8])\n",
    "    return LabeledDocument(values[0], textValue, low_birth)\n",
    "\n",
    "\n",
    "# Load the raw lowbwt.csv file, parse it using the function above\n",
    "import ibmos2spark\n",
    "\n",
    "# @hidden_cell\n",
    "credentials = {\n",
    "    'auth_url': 'https://identity.open.softlayer.com',\n",
    "    'project_id': '7984a968f14449858d826f8ba838fbb3',\n",
    "    'region': 'dallas',\n",
    "    'user_id': '51e14119a08842f0a9311ea21a5debfc',\n",
    "    'username': 'member_c8a299d593b1d03a3e131a4df7aec8a60c5f34ce',\n",
    "    'password': 'DWy^2pn8K=WMrUIu'\n",
    "}\n",
    "\n",
    "configuration_name = 'os_85a89ae392d2473988f606b7870013f9_configs'\n",
    "bmos = ibmos2spark.bluemix(sc, credentials, configuration_name)\n",
    "\n",
    "data= sc.textFile(bmos.url('DefaultProjectagarner18studentumucedu', 'lowbwt.csv'))\n",
    "data.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PersonID=u'ID', PersonInfo=u'AGE RACE SMOKE PTL HT UI FTV', label=1.0),\n",
       " Row(PersonID=u'85', PersonInfo=u'19 2 0 0 0 1 0', label=0.0),\n",
       " Row(PersonID=u'86', PersonInfo=u'33 3 0 0 0 0 3', label=0.0),\n",
       " Row(PersonID=u'87', PersonInfo=u'20 1 1 0 0 0 1', label=0.0),\n",
       " Row(PersonID=u'88', PersonInfo=u'21 1 1 0 0 1 2', label=0.0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data into a dataframe\n",
    "documents = data.filter(lambda s: \"Name\" not in s).map(parseDocument)\n",
    "training = documents.toDF() # ToDataFrame\n",
    "training.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up Logistic Regression using Pipeline of SparkML\n",
    "tokenizer = Tokenizer(inputCol=\"PersonInfo\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set up Logistic Regression Model\n",
    "# the stages are executed in order\n",
    "model = pipeline.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----+\n",
      "|PersonID|          PersonInfo|label|\n",
      "+--------+--------------------+-----+\n",
      "|      ID|AGE RACE SMOKE PT...|  1.0|\n",
      "|      85|      19 2 0 0 0 1 0|  0.0|\n",
      "|      86|      33 3 0 0 0 0 3|  0.0|\n",
      "|      87|      20 1 1 0 0 0 1|  0.0|\n",
      "|      88|      21 1 1 0 0 1 2|  0.0|\n",
      "|      89|      18 1 1 0 0 1 0|  0.0|\n",
      "|      91|      21 3 0 0 0 0 0|  0.0|\n",
      "|      92|      22 1 0 0 0 0 1|  0.0|\n",
      "|      93|      17 3 0 0 0 0 1|  0.0|\n",
      "|      94|      29 1 1 0 0 0 1|  0.0|\n",
      "|      95|      26 1 1 0 0 0 0|  0.0|\n",
      "|      96|      19 3 0 0 0 0 0|  0.0|\n",
      "|      97|      19 3 0 0 0 0 1|  0.0|\n",
      "|      98|      22 3 0 0 1 0 0|  0.0|\n",
      "|      99|      30 3 0 1 0 1 2|  0.0|\n",
      "|     100|      18 1 1 0 0 0 0|  0.0|\n",
      "|     101|      18 1 1 0 0 0 0|  0.0|\n",
      "|     102|      15 2 0 0 0 0 0|  0.0|\n",
      "|     103|      25 1 1 0 0 0 3|  0.0|\n",
      "|     104|      20 3 0 0 0 1 0|  0.0|\n",
      "+--------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify the training document \n",
    "# to checkpoint your progress with the application\n",
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PersonInfo here is a combination of age, race, smoke, ptl, ht, ut, and ftv.\n",
    "# *x in Document(*x) is for header of Row(\"PersonID\", \"PersonInfo\")\n",
    "Document = Row(\"PersonID\", \"PersonInfo\")\n",
    "test = sc.parallelize([(227, \"32 1 0 0 0 0 3 female\"),\n",
    "              (228, \"23 3 0 0 1 0 0 female\"),\n",
    "              (229, \"15 2 1 0 0 0 0 male\"),\n",
    "              (230, \"32 1 0 0 0 1 0 male\"),\n",
    "              (231, \"19 3 1 0 0 0 0 female\"),\n",
    "              (232, \"39 1 0 1 0 1 1 male\")]).map(lambda x: Document(*x)).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/src/spark160master/spark/python/pyspark/ml/classification.py:207: UserWarning: weights is deprecated. Use coefficients instead.\n",
      "  warnings.warn(\"weights is deprecated. Use coefficients instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(PersonInfo=u'32 1 0 0 0 0 3 female', prediction=0.0, probability=DenseVector([0.7688, 0.2312]))\n",
      "Row(PersonInfo=u'23 3 0 0 1 0 0 female', prediction=0.0, probability=DenseVector([0.5631, 0.4369]))\n",
      "Row(PersonInfo=u'15 2 1 0 0 0 0 male', prediction=1.0, probability=DenseVector([0.2887, 0.7113]))\n",
      "Row(PersonInfo=u'32 1 0 0 0 1 0 male', prediction=0.0, probability=DenseVector([0.8455, 0.1545]))\n",
      "Row(PersonInfo=u'19 3 1 0 0 0 0 female', prediction=0.0, probability=DenseVector([0.7756, 0.2244]))\n",
      "Row(PersonInfo=u'39 1 0 1 0 1 1 male', prediction=1.0, probability=DenseVector([0.4541, 0.5459]))\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test documents and print columns of interest\n",
    "prediction = model.transform(test)\n",
    "selected = prediction.select(\"PersonInfo\", \"prediction\", \"probability\")\n",
    "for row in selected.collect():\n",
    "    print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Measure = 0.530612244898\n",
      "Test Accuracy = 0.757894736842\n",
      "Test Error = 0.242105263158\n",
      "Precision = 0.684210526316\n",
      "Recall = 0.433333333333\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Logistic Regression model\n",
    "# Select (prediction, true label) and compute test error\n",
    "pred_lr=model.transform(training).select(\"prediction\", \"label\")\n",
    "eval_lr=MulticlassClassificationEvaluator (\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"precision\")\n",
    "accuracy_lr=eval_lr.evaluate(pred_lr)\n",
    "# create RDD\n",
    "predictionAndLabels_lr=pred_lr.rdd\n",
    "metrics_lr=MulticlassMetrics(predictionAndLabels_lr)\n",
    "precision_lr=metrics_lr.precision(1)\n",
    "recall_lr=metrics_lr.recall(1)\n",
    "f1Measure_lr = metrics_lr.fMeasure(1.0, 1.0)\n",
    "print(\"F1 Measure = %s\" % f1Measure_lr)\n",
    "print (\"Test Accuracy = %s\" %accuracy_lr)\n",
    "print (\"Test Error = %s\" % (1-accuracy_lr))\n",
    "print (\"Precision = %s\" %precision_lr)\n",
    "print (\"Recall = %s\" %recall_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 118.,   12.],\n",
       "       [  34.,   26.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the confusion matrix\n",
    "metrics_lr.confusionMatrix().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR = 0.648245614035\n",
      "Area under ROC = 0.670512820513\n"
     ]
    }
   ],
   "source": [
    "bin_lr=BinaryClassificationMetrics(predictionAndLabels_lr)\n",
    "\n",
    "# Area under precision-recall curve\n",
    "print(\"Area under PR = %s\" % bin_lr.areaUnderPR)\n",
    "# Area under precision-recall curve\n",
    "print(\"Area under ROC = %s\" % bin_lr.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 1.6",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "name": "machineLearningHAVCBluemix.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
